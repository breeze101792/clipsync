import pyaudio
import time
import threading
from funasr import AutoModel
import webrtcvad
import queue
import numpy as np
import librosa
import wave

class ASRService:
    # setup model
    ASR_MODEL = "paraformer-zh"  # èªžéŸ³è­˜åˆ¥æ¨¡åž‹
    VAD_MODEL = "fsmn-vad"       # èªžéŸ³æ´»å‹•æª¢æ¸¬ï¼ˆå¯é¸ï¼‰
    PUNC_MODEL = "ct-punc"       # æ¨™é»žç¬¦è™Ÿæ¨¡åž‹ï¼ˆå¯é¸ï¼‰

    VAD_MODE=3

    # setup audio args
    # CHUNK = 1024  # æ¯æ¬¡è®€å–çš„éŸ³è¨Šå¤§å°
    FORMAT = pyaudio.paInt16  # 16-bit PCM
    CHANNELS = 1  # å–®è²é“
    AUDIO_RATE = 48000  # FunASR éœ€è¦ 16kHz
    TARGET_RATE = 16000  # FunASR éœ€è¦ 16kHz
    DEVICE_INDEX = 5  # æ‰‹å‹•è¨­å®šè£ç½® IDï¼ˆå¯ç”¨ list_audio_devices() æŸ¥è©¢ï¼‰
    SILENCE_DURATION = 3  # è‹¥ç„¡è²éŸ³è¶…éŽ 3 ç§’å‰‡çµæŸéŒ„éŸ³
    CHUNK = int(AUDIO_RATE * 20 / 1000)

    def __init__(self):
        # vars
        self.flag_run = False
        self.def_queue_limit = 100
        self.tmp_file = "/tmp/output.wav"
        self.flag_output = True

        self.text_queue = queue.Queue()

        # load modle
        self.model = AutoModel(model=self.ASR_MODEL, vad_model=self.VAD_MODEL, punc_model=self.PUNC_MODEL, disable_update=True, disable_log=True, disable_pbar=True)

        # Init mic
        self.audio = pyaudio.PyAudio()
    def get(self):
        if self.text_queue.empty() is False:
            return self.text_queue.get()
        else:
            return None

    def start(self):
        service_thread = threading.Thread(target=self.listen_continuous, daemon=True)
        service_thread.start()
    def stop(self):
        self.flag_run = False

    def save_wave(self, filename, audio_data, sample_rate):
        audio_np = np.frombuffer(audio_data, dtype=np.int16)
        if sample_rate != self.TARGET_RATE:
            audio_np = librosa.resample(audio_np.astype(np.float32), orig_sr=sample_rate, target_sr=self.TARGET_RATE)
            sample_rate = self.TARGET_RATE

        with wave.open(filename, "wb") as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(sample_rate)
            wf.writeframes(audio_np.astype(np.int16).tobytes())

        # print(f"âœ… éŸ³æª”å·²å„²å­˜: {filename} (å–æ¨£çŽ‡: {sample_rate} Hz)")

    def command_handler(self, message):
        is_cmd = False
        # return true mean it's a command, and just ignore it.
        if message == "output enable":
            self.flag_output = True
            is_cmd = True
        elif message == "output disable":
            self.flag_output = False
            is_cmd = True
        elif message == "clear data":
            self.text_queue.queue.clear()
            is_cmd = True

        # check if we need to block recording
        if self.flag_output is False:
            is_cmd = True

        return is_cmd
    def recognize_audio(self, filename):
        result = self.model.generate(input=filename)
        return result[0]['text']

    def listen_continuous(self):
        # åˆå§‹åŒ– VAD
        vad = webrtcvad.Vad()
        vad.set_mode(self.VAD_MODE)

        print("ðŸŽ¤ Continuous listen...")

        stream = self.audio.open(format=self.FORMAT,
                                 channels=self.CHANNELS,
                                 rate=self.AUDIO_RATE,
                                 input=True,
                                 frames_per_buffer=self.CHUNK,
                                 input_device_index=self.DEVICE_INDEX)
        self.flag_run = True
        while self.flag_run:
            audio_list = []
            is_recording = False
            start_time = time.time()
            silence_start_time = time.time()

            try:
                while self.flag_run:
                    data = stream.read(self.CHUNK, exception_on_overflow=False)
                    is_speech = vad.is_speech(data, self.AUDIO_RATE)

                    if is_speech is True and is_recording is False:
                        # Start recording
                        print("ðŸŽ™ï¸ Audio defected...")
                        is_recording = True
                        start_time = time.time()
                        silence_start_time = time.time()

                    # record data.
                    if is_recording is True:
                        audio_list.append(data)

                    # åµæ¸¬åœæ­¢ï¼ˆè‹¥ç„¡è²éŸ³è¶…éŽ SILENCE_DURATION ç§’å‰‡çµæŸéŒ„éŸ³ï¼‰
                    silence_duration = time.time() - silence_start_time
                    if is_recording and silence_duration > self.SILENCE_DURATION:
                        print("ðŸ›‘ Recording ended, start recognition...")
                        break
            except KeyboardInterrupt:
                print("\nðŸ›‘ Stop listening.")
                break

            # çµ„åˆéŸ³è¨Šæ•¸æ“š
            audio_data = b''.join(audio_list)
            self.save_wave(self.tmp_file, audio_data, self.AUDIO_RATE)
            text_result = self.recognize_audio(self.tmp_file)
            if text_result != "" and self.command_handler(text_result) is False:
                if self.text_queue.qsize() > self.def_queue_limit:
                    print("Hit queue limit, just clear queue.")
                    self.text_queue.queue.clear()
                self.text_queue.put(text_result)

        stream.stop_stream()
        stream.close()
        self.audio.terminate()

if __name__ == "__main__":
    asr = ASRService()
    # asr.listen_continuous()
    asr.start()
    input("Enter to finish.")
